{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Tarea para el Hogar 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSICPpyTGQmC"
   },
   "source": [
    "Esta Tarea para el Hogar 02 se entrega el final de la cuarta clase\n",
    "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 05 que será el miercoles 03 de septiembre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  1. Cazatalentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "En la Clase 03 nos hemos enfrentado a  \"La Maldicion del Ganandor\",  elegir el modelo con el mejor puntaje simple no suele ser la mejor estrategia.\n",
    "<br> Lea y ejecute el notebook  **src/CazaTalentos/CazaTalentos.ipynb**\n",
    "<br> en caso de interesarle, participe del Desafío Ordenamiento  que vence el sábado 06 de septiembre a las 19:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9GkTOk5J9t3"
   },
   "source": [
    "## 2. Hiperparámetros del LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmEFy0ukKL5T"
   },
   "source": [
    "Los objetivos de esta tarea son:\n",
    "\n",
    "\n",
    "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
    "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
    "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
    "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
    "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
    "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yvlS6JQLRMd"
   },
   "source": [
    "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
    "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eydI4YNAsFaf"
   },
   "source": [
    "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
    "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzU4S0SeMcpp"
   },
   "source": [
    "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
    "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
    "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNptUgI_NWWG"
   },
   "source": [
    "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
    "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
    "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
    "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
    "\n",
    "\n",
    "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
    "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpUThBojODyK"
   },
   "source": [
    "El desafío de esta tarea es:\n",
    "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
    "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
    "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX0qg_c0yqob"
   },
   "source": [
    "#### 2.1  Seteo del ambiente en Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGY7H9xza7Zr"
   },
   "source": [
    "Esta parte se debe correr con el runtime en Python3\n",
    "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PupIBNba7Zr"
   },
   "source": [
    "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LpZCst5a7Zs"
   },
   "outputs": [],
   "source": [
    "# primero establecer el Runtime de Python 3\n",
    "from google.colab import drive\n",
    "drive.mount('/content/.drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYC_F-wla7Zs"
   },
   "source": [
    "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
    "\n",
    "<br>los siguientes comando estan en shell script de Linux\n",
    "*   Crear las carpetas en el Google Drive\n",
    "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
    "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWLelftXa7Zt"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "mkdir -p \"/content/.drive/My Drive/dm\"\n",
    "mkdir -p \"/content/buckets\"\n",
    "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
    "\n",
    "mkdir -p ~/.kaggle\n",
    "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
    "chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "\n",
    "mkdir -p /content/buckets/b1/exp\n",
    "mkdir -p /content/buckets/b1/datasets\n",
    "mkdir -p /content/datasets\n",
    "\n",
    "\n",
    "\n",
    "archivo_origen=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/dataset_pequeno.csv\"\n",
    "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
    "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
    "\n",
    "if ! test -f $archivo_destino_bucket; then\n",
    "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
    "fi\n",
    "\n",
    "\n",
    "if ! test -f $archivo_destino; then\n",
    "  cp  $archivo_destino_bucket  $archivo_destino\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### 2.2 Optimizacion Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kwPpHAtSmix"
   },
   "source": [
    "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "### 2.2.1 Inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy8YTZfESxeJ"
   },
   "source": [
    "limpio el ambiente de R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gBq__iAdQliq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Tue Sep 02 00:32:48 2025'"
      ],
      "text/latex": [
       "'Tue Sep 02 00:32:48 2025'"
      ],
      "text/markdown": [
       "'Tue Sep 02 00:32:48 2025'"
      ],
      "text/plain": [
       "[1] \"Tue Sep 02 00:32:48 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7rdVrBojS1IV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 656930</td><td>35.1</td><td>1439380</td><td>76.9</td><td>1431356</td><td>76.5</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1224983</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1924961</td><td>14.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  656930 & 35.1 & 1439380 & 76.9 & 1431356 & 76.5\\\\\n",
       "\tVcells & 1224983 &  9.4 & 8388608 & 64.0 & 1924961 & 14.7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  656930 | 35.1 | 1439380 | 76.9 | 1431356 | 76.5 |\n",
       "| Vcells | 1224983 |  9.4 | 8388608 | 64.0 | 1924961 | 14.7 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  656930 35.1 1439380    76.9 1431356  76.5\n",
       "Vcells 1224983  9.4 8388608    64.0 1924961  14.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### 2.2.2 Carga de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lVyxLaJ1j1J_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: primes\n",
      "\n",
      "Loading required package: rlist\n",
      "\n",
      "Loading required package: yaml\n",
      "\n",
      "Loading required package: lightgbm\n",
      "\n",
      "Loading required package: DiceKriging\n",
      "\n",
      "Loading required package: mlrMBO\n",
      "\n",
      "Loading required package: mlr\n",
      "\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "Loading required package: smoof\n",
      "\n",
      "Loading required package: checkmate\n",
      "\n",
      "\n",
      "Attaching package: ‘checkmate’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:DiceKriging’:\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cargo las librerias que necesito\n",
    "require(\"data.table\")\n",
    "require(\"parallel\")\n",
    "\n",
    "if( !require(\"primes\") ) install.packages(\"primes\")\n",
    "require(\"primes\")\n",
    "\n",
    "if( !require(\"utils\") ) install.packages(\"utils\")\n",
    "require(\"utils\")\n",
    "\n",
    "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
    "require(\"rlist\")\n",
    "\n",
    "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
    "require(\"yaml\")\n",
    "\n",
    "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")\n",
    "\n",
    "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz-6Qt6BUaA3"
   },
   "source": [
    "### 2.2.3 Definicion de Parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOdlKd7lUm2I"
   },
   "source": [
    "aqui debe cargar SU semilla primigenia\n",
    "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ASYkebOu2mF6"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- 4943\n",
    "PARAM$semilla_primigenia <- 100109\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ezOhQdbA293o"
   },
   "outputs": [],
   "source": [
    "PARAM$kaggle$competencia <- \"data-mining-analista-sr-2025-b\"\n",
    "PARAM$kaggle$cortes <- seq(10000, 12000, by= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jtB0Lub42rHO"
   },
   "outputs": [],
   "source": [
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "# undersampling de 1.0  implica tomar TODOS los datos\n",
    "\n",
    "PARAM$trainingstrategy$undersampling <- 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OFxm-xiNUOJX"
   },
   "outputs": [],
   "source": [
    "# Parametros LightGBM\n",
    "\n",
    "PARAM$hyperparametertuning$xval_folds <- 5\n",
    "\n",
    "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
    "PARAM$lgbm$param_fijos <-  list(\n",
    "  boosting= \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective= \"binary\",\n",
    "  metric= \"auc\",\n",
    "  first_metric_only= FALSE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  force_row_wise= TRUE, # para reducir warnings\n",
    "  verbosity= -100,\n",
    "\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "\n",
    "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
    "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1= 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2= 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
    "\n",
    "  bagging_fraction= 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance= FALSE, #\n",
    "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop= 50, # <=0 means no limit\n",
    "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees= FALSE,\n",
    "\n",
    "  num_iterations= 1200,\n",
    "  learning_rate= 0.02,\n",
    "  feature_fraction= 0.5,\n",
    "  num_leaves= 750,\n",
    "  min_data_in_leaf= 5000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5Yj-JV4yvOt"
   },
   "source": [
    "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
    "<br> si es un numero entero debe ir  makeIntegerParam\n",
    "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
    "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jENpR26ZyuS8"
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
    "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
    "  makeIntegerParam(\"num_iterations\", lower= 1500L, upper= 4500L),\n",
    "  makeNumericParam(\"learning_rate\", lower= 0.004, upper= 0.012),\n",
    "  makeNumericParam(\"feature_fraction\", lower= 0.55, upper= 0.80),\n",
    "  makeIntegerParam(\"num_leaves\", lower= 400L, upper= 900L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower= 50L, upper= 400L),\n",
    "\n",
    "  # NUEVOS (capacidad y regularización)\n",
    "  makeIntegerParam(\"max_depth\",         lower = 5L,    upper = 8L),\n",
    "  makeNumericParam(\"min_gain_to_split\", lower = 0.5,   upper = 2.0),\n",
    "\n",
    "  # bagging por filas (se activa si bagging_freq > 0)\n",
    "  makeNumericParam(\"bagging_fraction\",  lower = 0.80,  upper = 0.95),\n",
    "  makeIntegerParam(\"bagging_freq\",      lower = 6L,    upper = 12L),\n",
    "\n",
    "  # regularización\n",
    "  makeNumericParam(\"lambda_l1\",         lower = 0.5,   upper = 3.0),\n",
    "  makeNumericParam(\"lambda_l2\",         lower = 1.0,   upper = 4.0),\n",
    "\n",
    "  # regularizador recomendado por la doc\n",
    "  makeNumericParam(\"min_sum_hessian_in_leaf\", lower = 0.02, upper = 0.06)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_RPFUb3zMoW"
   },
   "source": [
    "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
    "<br> 30 es un valor muy tacaño, pero corre rápido\n",
    "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "q5Rd3pnbzSiG"
   },
   "outputs": [],
   "source": [
    "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RWZXL1VZjMI"
   },
   "source": [
    "### 2.2.4  Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "j3toG9-lZm4K"
   },
   "outputs": [],
   "source": [
    "# carpeta de trabajo\n",
    "\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FM3lxKoLZ643"
   },
   "outputs": [],
   "source": [
    "# lectura del dataset\n",
    "\n",
    "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OsJ-91UeZ-I_"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vrWE7BE0aB2J"
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "\n",
    "dataset_train[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jP7YlQBnaW6W"
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "# notar que para esto utilizo la SEGUNDA semilla\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train[, azar := runif(nrow(dataset_train))]\n",
    "dataset_train[, training := 0L]\n",
    "\n",
    "dataset_train[\n",
    "  foto_mes %in% c(202107) &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xElu4s5W4rX7"
   },
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PppMHcGYaaol"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "83273"
      ],
      "text/latex": [
       "83273"
      ],
      "text/markdown": [
       "83273"
      ],
      "text/plain": [
       "[1] 83273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "154"
      ],
      "text/latex": [
       "154"
      ],
      "text/markdown": [
       "154"
      ],
      "text/plain": [
       "[1] 154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "nrow(dtrain)\n",
    "ncol(dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta-EkOu3cphF"
   },
   "source": [
    "2.2.5 Configuracion Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cjgfurjdfiXb"
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la AUC en cross validation del modelo entrenado\n",
    "\n",
    "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  # entreno LightGBM\n",
    "  modelocv <- lgb.cv(\n",
    "    data= dtrain,\n",
    "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
    "    stratified= TRUE,\n",
    "    param= param_completo\n",
    "  )\n",
    "\n",
    "  # obtengo la ganancia\n",
    "  AUC <- modelocv$best_score\n",
    "\n",
    "  # hago espacio en la memoria\n",
    "  rm(modelocv)\n",
    "  gc(full= TRUE, verbose= FALSE)\n",
    "\n",
    "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
    "\n",
    "  return(AUC)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WLi_o1hocvN-"
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "\n",
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "kbayesiana <- \"bayesiana.RDATA\"\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hyperparametertuning$iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uUeVo5pc4zc"
   },
   "source": [
    "2.2.6 Corrida Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcABNaKGciaz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing y column(s) for design. Not provided.\n",
      "\n",
      "Tue Sep 02 00:35:48 2025 AUC 0.929213004359975\n",
      "\n",
      "Tue Sep 02 00:37:35 2025 AUC 0.930390314266432\n",
      "\n",
      "Tue Sep 02 00:39:47 2025 AUC 0.929798993689843\n",
      "\n",
      "Tue Sep 02 00:41:49 2025 AUC 0.930638933003281\n",
      "\n",
      "Tue Sep 02 00:43:05 2025 AUC 0.930824408272144\n",
      "\n",
      "Tue Sep 02 00:44:22 2025 AUC 0.931167618670321\n",
      "\n",
      "Tue Sep 02 00:45:44 2025 AUC 0.931089063909572\n",
      "\n",
      "Tue Sep 02 00:46:45 2025 AUC 0.930228453240368\n",
      "\n",
      "Tue Sep 02 00:49:00 2025 AUC 0.931294622114749\n",
      "\n",
      "Tue Sep 02 00:51:23 2025 AUC 0.930070687364176\n",
      "\n",
      "Tue Sep 02 00:52:40 2025 AUC 0.930788043372985\n",
      "\n",
      "Tue Sep 02 00:54:40 2025 AUC 0.931162983660221\n",
      "\n",
      "Tue Sep 02 00:56:56 2025 AUC 0.930232060374668\n",
      "\n",
      "Tue Sep 02 00:58:12 2025 AUC 0.930240951968231\n",
      "\n",
      "Tue Sep 02 00:59:35 2025 AUC 0.929744646803467\n",
      "\n",
      "Tue Sep 02 01:00:46 2025 AUC 0.930518960298414\n",
      "\n",
      "Tue Sep 02 01:02:24 2025 AUC 0.930778464081178\n",
      "\n",
      "Tue Sep 02 01:04:22 2025 AUC 0.930887460583832\n",
      "\n",
      "Tue Sep 02 01:06:06 2025 AUC 0.929119582725849\n",
      "\n",
      "Tue Sep 02 01:08:11 2025 AUC 0.931278815644672\n",
      "\n",
      "Tue Sep 02 01:10:07 2025 AUC 0.929881270566317\n",
      "\n",
      "Tue Sep 02 01:12:03 2025 AUC 0.930558786645307\n",
      "\n",
      "Tue Sep 02 01:13:40 2025 AUC 0.931954205688991\n",
      "\n",
      "Tue Sep 02 01:16:01 2025 AUC 0.931311693394405\n",
      "\n",
      "Tue Sep 02 01:18:07 2025 AUC 0.931059332556483\n",
      "\n",
      "Tue Sep 02 01:19:56 2025 AUC 0.931007053504128\n",
      "\n",
      "Tue Sep 02 01:21:04 2025 AUC 0.928910422116732\n",
      "\n",
      "Tue Sep 02 01:23:38 2025 AUC 0.930875510504801\n",
      "\n",
      "Tue Sep 02 01:25:07 2025 AUC 0.930905716776264\n",
      "\n",
      "Tue Sep 02 01:26:20 2025 AUC 0.930542896081038\n",
      "\n",
      "Tue Sep 02 01:29:23 2025 AUC 0.930444568862418\n",
      "\n",
      "Tue Sep 02 01:31:01 2025 AUC 0.929713637791444\n",
      "\n",
      "Tue Sep 02 01:32:28 2025 AUC 0.930033861743494\n",
      "\n",
      "Tue Sep 02 01:33:48 2025 AUC 0.929795815415319\n",
      "\n",
      "Tue Sep 02 01:35:16 2025 AUC 0.931327999818127\n",
      "\n",
      "Tue Sep 02 01:37:59 2025 AUC 0.931545441980088\n",
      "\n",
      "Tue Sep 02 01:39:35 2025 AUC 0.931166848448514\n",
      "\n",
      "Tue Sep 02 01:40:42 2025 AUC 0.930781069423194\n",
      "\n",
      "Tue Sep 02 01:41:53 2025 AUC 0.929951844843439\n",
      "\n",
      "Tue Sep 02 01:44:11 2025 AUC 0.929618673577948\n",
      "\n",
      "Tue Sep 02 01:45:19 2025 AUC 0.929634450819771\n",
      "\n",
      "Tue Sep 02 01:48:15 2025 AUC 0.930480462320009\n",
      "\n",
      "Tue Sep 02 01:49:39 2025 AUC 0.930726055873235\n",
      "\n",
      "Tue Sep 02 01:50:57 2025 AUC 0.931237876509414\n",
      "\n",
      "Tue Sep 02 01:52:05 2025 AUC 0.930219008724087\n",
      "\n",
      "Tue Sep 02 01:54:05 2025 AUC 0.930524501146285\n",
      "\n",
      "Tue Sep 02 01:57:01 2025 AUC 0.930141292000516\n",
      "\n",
      "Tue Sep 02 01:58:17 2025 AUC 0.930481630734343\n",
      "\n",
      "[mbo] 0: num_iterations=3620; learning_rate=0.00886; feature_fraction=0.749; num_leaves=631; min_data_in_leaf=274; max_depth=7; min_gain_to_split=1.47; bagging_fraction=0.944; bagging_freq=9; lambda_l1=1.89; lambda_l2=2.8; min_sum_hessian_in_leaf=0.0379 : y = 0.929 : 90.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3057; learning_rate=0.00818; feature_fraction=0.66; num_leaves=555; min_data_in_leaf=242; max_depth=7; min_gain_to_split=1.24; bagging_fraction=0.846; bagging_freq=8; lambda_l1=1.73; lambda_l2=2.45; min_sum_hessian_in_leaf=0.0357 : y = 0.93 : 107.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2527; learning_rate=0.00844; feature_fraction=0.565; num_leaves=860; min_data_in_leaf=180; max_depth=5; min_gain_to_split=0.796; bagging_fraction=0.927; bagging_freq=7; lambda_l1=1.76; lambda_l2=2.65; min_sum_hessian_in_leaf=0.0494 : y = 0.93 : 131.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2892; learning_rate=0.00557; feature_fraction=0.631; num_leaves=544; min_data_in_leaf=125; max_depth=7; min_gain_to_split=1.01; bagging_fraction=0.861; bagging_freq=7; lambda_l1=2.46; lambda_l2=1.29; min_sum_hessian_in_leaf=0.0295 : y = 0.931 : 122.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3192; learning_rate=0.00931; feature_fraction=0.673; num_leaves=751; min_data_in_leaf=132; max_depth=6; min_gain_to_split=1.62; bagging_fraction=0.943; bagging_freq=10; lambda_l1=1.49; lambda_l2=3.18; min_sum_hessian_in_leaf=0.0335 : y = 0.931 : 75.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1963; learning_rate=0.00744; feature_fraction=0.685; num_leaves=642; min_data_in_leaf=192; max_depth=8; min_gain_to_split=1.12; bagging_fraction=0.849; bagging_freq=11; lambda_l1=1.2; lambda_l2=3.11; min_sum_hessian_in_leaf=0.0416 : y = 0.931 : 77.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3802; learning_rate=0.00988; feature_fraction=0.723; num_leaves=534; min_data_in_leaf=217; max_depth=6; min_gain_to_split=1.59; bagging_fraction=0.867; bagging_freq=8; lambda_l1=1.34; lambda_l2=1.81; min_sum_hessian_in_leaf=0.0326 : y = 0.931 : 82.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2576; learning_rate=0.00943; feature_fraction=0.748; num_leaves=560; min_data_in_leaf=108; max_depth=8; min_gain_to_split=1.66; bagging_fraction=0.901; bagging_freq=8; lambda_l1=2.42; lambda_l2=2.83; min_sum_hessian_in_leaf=0.0542 : y = 0.93 : 61.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3093; learning_rate=0.0047; feature_fraction=0.706; num_leaves=756; min_data_in_leaf=286; max_depth=7; min_gain_to_split=0.777; bagging_fraction=0.873; bagging_freq=8; lambda_l1=1.82; lambda_l2=1.47; min_sum_hessian_in_leaf=0.0384 : y = 0.931 : 134.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2980; learning_rate=0.0105; feature_fraction=0.627; num_leaves=712; min_data_in_leaf=321; max_depth=7; min_gain_to_split=0.657; bagging_fraction=0.871; bagging_freq=9; lambda_l1=1.68; lambda_l2=2.41; min_sum_hessian_in_leaf=0.0516 : y = 0.93 : 143.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1839; learning_rate=0.00909; feature_fraction=0.621; num_leaves=622; min_data_in_leaf=237; max_depth=6; min_gain_to_split=1.37; bagging_fraction=0.812; bagging_freq=7; lambda_l1=1.15; lambda_l2=3.65; min_sum_hessian_in_leaf=0.0475 : y = 0.931 : 77.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3677; learning_rate=0.00666; feature_fraction=0.716; num_leaves=722; min_data_in_leaf=359; max_depth=6; min_gain_to_split=1.18; bagging_fraction=0.88; bagging_freq=12; lambda_l1=1.09; lambda_l2=1.23; min_sum_hessian_in_leaf=0.0561 : y = 0.931 : 119.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3393; learning_rate=0.00717; feature_fraction=0.582; num_leaves=685; min_data_in_leaf=165; max_depth=8; min_gain_to_split=1.71; bagging_fraction=0.911; bagging_freq=12; lambda_l1=1.5; lambda_l2=3.04; min_sum_hessian_in_leaf=0.0245 : y = 0.93 : 135.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2422; learning_rate=0.0112; feature_fraction=0.693; num_leaves=851; min_data_in_leaf=210; max_depth=5; min_gain_to_split=0.975; bagging_fraction=0.851; bagging_freq=11; lambda_l1=0.616; lambda_l2=1.63; min_sum_hessian_in_leaf=0.0419 : y = 0.93 : 76.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2211; learning_rate=0.00626; feature_fraction=0.779; num_leaves=599; min_data_in_leaf=143; max_depth=6; min_gain_to_split=1.14; bagging_fraction=0.892; bagging_freq=6; lambda_l1=1.42; lambda_l2=3.34; min_sum_hessian_in_leaf=0.0304 : y = 0.93 : 82.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2047; learning_rate=0.0118; feature_fraction=0.648; num_leaves=439; min_data_in_leaf=281; max_depth=7; min_gain_to_split=0.916; bagging_fraction=0.907; bagging_freq=10; lambda_l1=1.92; lambda_l2=1.6; min_sum_hessian_in_leaf=0.0372 : y = 0.931 : 71.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3258; learning_rate=0.00682; feature_fraction=0.737; num_leaves=476; min_data_in_leaf=153; max_depth=6; min_gain_to_split=1.31; bagging_fraction=0.835; bagging_freq=12; lambda_l1=2.33; lambda_l2=1.32; min_sum_hessian_in_leaf=0.0505 : y = 0.931 : 97.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2454; learning_rate=0.00705; feature_fraction=0.676; num_leaves=726; min_data_in_leaf=63; max_depth=8; min_gain_to_split=0.588; bagging_fraction=0.913; bagging_freq=8; lambda_l1=0.835; lambda_l2=2.5; min_sum_hessian_in_leaf=0.0429 : y = 0.931 : 118.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3835; learning_rate=0.00486; feature_fraction=0.778; num_leaves=495; min_data_in_leaf=253; max_depth=5; min_gain_to_split=1.5; bagging_fraction=0.932; bagging_freq=11; lambda_l1=2.18; lambda_l2=3.71; min_sum_hessian_in_leaf=0.0231 : y = 0.929 : 103.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2863; learning_rate=0.00777; feature_fraction=0.571; num_leaves=579; min_data_in_leaf=67; max_depth=5; min_gain_to_split=1.43; bagging_fraction=0.93; bagging_freq=9; lambda_l1=1.59; lambda_l2=3.5; min_sum_hessian_in_leaf=0.0398 : y = 0.931 : 124.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2647; learning_rate=0.00567; feature_fraction=0.576; num_leaves=405; min_data_in_leaf=369; max_depth=7; min_gain_to_split=1.88; bagging_fraction=0.894; bagging_freq=6; lambda_l1=2.64; lambda_l2=1.51; min_sum_hessian_in_leaf=0.048 : y = 0.93 : 116.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3463; learning_rate=0.00524; feature_fraction=0.718; num_leaves=828; min_data_in_leaf=221; max_depth=8; min_gain_to_split=1.19; bagging_fraction=0.898; bagging_freq=8; lambda_l1=2.96; lambda_l2=3.39; min_sum_hessian_in_leaf=0.0451 : y = 0.931 : 116.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=4011; learning_rate=0.0109; feature_fraction=0.708; num_leaves=652; min_data_in_leaf=350; max_depth=6; min_gain_to_split=1.27; bagging_fraction=0.865; bagging_freq=12; lambda_l1=0.885; lambda_l2=1.13; min_sum_hessian_in_leaf=0.0211 : y = 0.932 : 97.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=4134; learning_rate=0.00795; feature_fraction=0.729; num_leaves=812; min_data_in_leaf=199; max_depth=5; min_gain_to_split=0.537; bagging_fraction=0.84; bagging_freq=7; lambda_l1=1.96; lambda_l2=2.21; min_sum_hessian_in_leaf=0.0219 : y = 0.931 : 141.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3183; learning_rate=0.00592; feature_fraction=0.64; num_leaves=412; min_data_in_leaf=267; max_depth=8; min_gain_to_split=0.885; bagging_fraction=0.831; bagging_freq=11; lambda_l1=2.55; lambda_l2=2.61; min_sum_hessian_in_leaf=0.0324 : y = 0.931 : 125.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=4115; learning_rate=0.012; feature_fraction=0.684; num_leaves=696; min_data_in_leaf=94; max_depth=7; min_gain_to_split=1.05; bagging_fraction=0.855; bagging_freq=10; lambda_l1=0.781; lambda_l2=2.7; min_sum_hessian_in_leaf=0.0441 : y = 0.931 : 109.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2761; learning_rate=0.01; feature_fraction=0.698; num_leaves=511; min_data_in_leaf=293; max_depth=5; min_gain_to_split=1.91; bagging_fraction=0.949; bagging_freq=6; lambda_l1=2.24; lambda_l2=2.15; min_sum_hessian_in_leaf=0.0256 : y = 0.929 : 67.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=4256; learning_rate=0.00451; feature_fraction=0.667; num_leaves=776; min_data_in_leaf=151; max_depth=6; min_gain_to_split=1.08; bagging_fraction=0.906; bagging_freq=11; lambda_l1=0.506; lambda_l2=3.52; min_sum_hessian_in_leaf=0.0569 : y = 0.931 : 153.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2274; learning_rate=0.00763; feature_fraction=0.617; num_leaves=799; min_data_in_leaf=55; max_depth=5; min_gain_to_split=0.616; bagging_fraction=0.824; bagging_freq=9; lambda_l1=2.88; lambda_l2=2.98; min_sum_hessian_in_leaf=0.0558 : y = 0.931 : 89.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2168; learning_rate=0.0106; feature_fraction=0.635; num_leaves=892; min_data_in_leaf=112; max_depth=5; min_gain_to_split=1.83; bagging_fraction=0.841; bagging_freq=6; lambda_l1=1.61; lambda_l2=1.7; min_sum_hessian_in_leaf=0.0345 : y = 0.931 : 72.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=4432; learning_rate=0.00806; feature_fraction=0.553; num_leaves=491; min_data_in_leaf=299; max_depth=6; min_gain_to_split=1.84; bagging_fraction=0.826; bagging_freq=10; lambda_l1=1.01; lambda_l2=1.93; min_sum_hessian_in_leaf=0.0445 : y = 0.93 : 182.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3502; learning_rate=0.00646; feature_fraction=0.785; num_leaves=449; min_data_in_leaf=319; max_depth=8; min_gain_to_split=1.97; bagging_fraction=0.886; bagging_freq=9; lambda_l1=0.671; lambda_l2=3.88; min_sum_hessian_in_leaf=0.0487 : y = 0.93 : 98.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2365; learning_rate=0.00547; feature_fraction=0.761; num_leaves=888; min_data_in_leaf=397; max_depth=8; min_gain_to_split=1.73; bagging_fraction=0.877; bagging_freq=9; lambda_l1=2.32; lambda_l2=1.05; min_sum_hessian_in_leaf=0.0522 : y = 0.93 : 87.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1809; learning_rate=0.0113; feature_fraction=0.742; num_leaves=772; min_data_in_leaf=168; max_depth=7; min_gain_to_split=0.691; bagging_fraction=0.817; bagging_freq=8; lambda_l1=2.7; lambda_l2=1.4; min_sum_hessian_in_leaf=0.0205 : y = 0.93 : 79.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3742; learning_rate=0.0103; feature_fraction=0.799; num_leaves=516; min_data_in_leaf=307; max_depth=5; min_gain_to_split=1.64; bagging_fraction=0.821; bagging_freq=10; lambda_l1=2.14; lambda_l2=3.8; min_sum_hessian_in_leaf=0.0582 : y = 0.931 : 88.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=4323; learning_rate=0.00609; feature_fraction=0.658; num_leaves=469; min_data_in_leaf=79; max_depth=8; min_gain_to_split=0.735; bagging_fraction=0.922; bagging_freq=6; lambda_l1=2.04; lambda_l2=1.81; min_sum_hessian_in_leaf=0.0584 : y = 0.932 : 163.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=4445; learning_rate=0.0107; feature_fraction=0.65; num_leaves=793; min_data_in_leaf=392; max_depth=8; min_gain_to_split=1.5; bagging_fraction=0.884; bagging_freq=12; lambda_l1=2.6; lambda_l2=3.22; min_sum_hessian_in_leaf=0.0237 : y = 0.931 : 95.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1576; learning_rate=0.00692; feature_fraction=0.769; num_leaves=671; min_data_in_leaf=261; max_depth=7; min_gain_to_split=0.874; bagging_fraction=0.802; bagging_freq=7; lambda_l1=0.933; lambda_l2=1.97; min_sum_hessian_in_leaf=0.0528 : y = 0.931 : 67.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1658; learning_rate=0.00855; feature_fraction=0.6; num_leaves=595; min_data_in_leaf=341; max_depth=5; min_gain_to_split=1.41; bagging_fraction=0.94; bagging_freq=12; lambda_l1=1.25; lambda_l2=3.85; min_sum_hessian_in_leaf=0.0542 : y = 0.93 : 70.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=4242; learning_rate=0.0114; feature_fraction=0.587; num_leaves=873; min_data_in_leaf=328; max_depth=5; min_gain_to_split=1.97; bagging_fraction=0.857; bagging_freq=7; lambda_l1=2.81; lambda_l2=3.99; min_sum_hessian_in_leaf=0.0466 : y = 0.93 : 138.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1914; learning_rate=0.00414; feature_fraction=0.756; num_leaves=663; min_data_in_leaf=72; max_depth=6; min_gain_to_split=1.78; bagging_fraction=0.808; bagging_freq=11; lambda_l1=0.755; lambda_l2=3.28; min_sum_hessian_in_leaf=0.027 : y = 0.93 : 67.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3911; learning_rate=0.00979; feature_fraction=0.594; num_leaves=572; min_data_in_leaf=374; max_depth=7; min_gain_to_split=0.656; bagging_fraction=0.918; bagging_freq=6; lambda_l1=1.32; lambda_l2=2.89; min_sum_hessian_in_leaf=0.0313 : y = 0.93 : 176.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2075; learning_rate=0.00443; feature_fraction=0.611; num_leaves=455; min_data_in_leaf=118; max_depth=5; min_gain_to_split=0.823; bagging_fraction=0.89; bagging_freq=10; lambda_l1=2.75; lambda_l2=2.04; min_sum_hessian_in_leaf=0.0282 : y = 0.931 : 83.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1701; learning_rate=0.00872; feature_fraction=0.576; num_leaves=839; min_data_in_leaf=347; max_depth=7; min_gain_to_split=1.8; bagging_fraction=0.83; bagging_freq=10; lambda_l1=1.06; lambda_l2=1.1; min_sum_hessian_in_leaf=0.026 : y = 0.931 : 77.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1523; learning_rate=0.0116; feature_fraction=0.605; num_leaves=616; min_data_in_leaf=232; max_depth=8; min_gain_to_split=0.949; bagging_fraction=0.924; bagging_freq=7; lambda_l1=2.93; lambda_l2=2.28; min_sum_hessian_in_leaf=0.0599 : y = 0.93 : 68.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3972; learning_rate=0.00502; feature_fraction=0.767; num_leaves=423; min_data_in_leaf=379; max_depth=6; min_gain_to_split=1.56; bagging_fraction=0.803; bagging_freq=6; lambda_l1=2.52; lambda_l2=2.32; min_sum_hessian_in_leaf=0.0289 : y = 0.931 : 120.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2746; learning_rate=0.00424; feature_fraction=0.559; num_leaves=743; min_data_in_leaf=90; max_depth=8; min_gain_to_split=0.519; bagging_fraction=0.815; bagging_freq=10; lambda_l1=0.561; lambda_l2=3.58; min_sum_hessian_in_leaf=0.036 : y = 0.93 : 176.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=3357; learning_rate=0.00966; feature_fraction=0.793; num_leaves=823; min_data_in_leaf=184; max_depth=6; min_gain_to_split=1.33; bagging_fraction=0.936; bagging_freq=12; lambda_l1=2.09; lambda_l2=2.11; min_sum_hessian_in_leaf=0.0406 : y = 0.93 : 76.1 secs : initdesign\n",
      "\n",
      "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Sep 02 02:00:21 2025 AUC 0.929999226927732\n",
      "\n",
      "[mbo] 1: num_iterations=4243; learning_rate=0.0102; feature_fraction=0.708; num_leaves=706; min_data_in_leaf=323; max_depth=7; min_gain_to_split=1.07; bagging_fraction=0.863; bagging_freq=12; lambda_l1=0.865; lambda_l2=2.15; min_sum_hessian_in_leaf=0.0202 : y = 0.93 : 116.6 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:02:25 2025 AUC 0.930614792777686\n",
      "\n",
      "[mbo] 2: num_iterations=3140; learning_rate=0.00816; feature_fraction=0.629; num_leaves=760; min_data_in_leaf=354; max_depth=6; min_gain_to_split=1.26; bagging_fraction=0.882; bagging_freq=12; lambda_l1=0.706; lambda_l2=1.14; min_sum_hessian_in_leaf=0.0288 : y = 0.931 : 122.8 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:05:00 2025 AUC 0.930378436481419\n",
      "\n",
      "[mbo] 3: num_iterations=4363; learning_rate=0.004; feature_fraction=0.781; num_leaves=861; min_data_in_leaf=307; max_depth=5; min_gain_to_split=0.652; bagging_fraction=0.914; bagging_freq=10; lambda_l1=0.729; lambda_l2=2.81; min_sum_hessian_in_leaf=0.0376 : y = 0.93 : 153.6 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:07:04 2025 AUC 0.930220358758662\n",
      "\n",
      "[mbo] 4: num_iterations=4195; learning_rate=0.0103; feature_fraction=0.706; num_leaves=652; min_data_in_leaf=346; max_depth=6; min_gain_to_split=1.07; bagging_fraction=0.845; bagging_freq=9; lambda_l1=0.604; lambda_l2=1.39; min_sum_hessian_in_leaf=0.0317 : y = 0.93 : 122.7 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:08:11 2025 AUC 0.930206752476908\n",
      "\n",
      "[mbo] 5: num_iterations=1677; learning_rate=0.00591; feature_fraction=0.74; num_leaves=880; min_data_in_leaf=372; max_depth=8; min_gain_to_split=1.37; bagging_fraction=0.906; bagging_freq=12; lambda_l1=2.66; lambda_l2=2.98; min_sum_hessian_in_leaf=0.0425 : y = 0.93 : 65.5 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:09:29 2025 AUC 0.930813985753315\n",
      "\n",
      "[mbo] 6: num_iterations=3641; learning_rate=0.00938; feature_fraction=0.707; num_leaves=560; min_data_in_leaf=343; max_depth=6; min_gain_to_split=1.75; bagging_fraction=0.863; bagging_freq=12; lambda_l1=2.37; lambda_l2=1.14; min_sum_hessian_in_leaf=0.0272 : y = 0.931 : 76.6 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 7 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Sep 02 02:11:36 2025 AUC 0.930616840194809\n",
      "\n",
      "[mbo] 7: num_iterations=4293; learning_rate=0.00743; feature_fraction=0.653; num_leaves=820; min_data_in_leaf=263; max_depth=6; min_gain_to_split=1.26; bagging_fraction=0.845; bagging_freq=9; lambda_l1=2.41; lambda_l2=1.74; min_sum_hessian_in_leaf=0.0529 : y = 0.931 : 122.9 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:13:17 2025 AUC 0.931097665635078\n",
      "\n",
      "[mbo] 8: num_iterations=3903; learning_rate=0.0107; feature_fraction=0.721; num_leaves=668; min_data_in_leaf=374; max_depth=6; min_gain_to_split=1.26; bagging_fraction=0.806; bagging_freq=12; lambda_l1=0.687; lambda_l2=1.29; min_sum_hessian_in_leaf=0.023 : y = 0.931 : 99.6 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:15:36 2025 AUC 0.931044291366946\n",
      "\n",
      "[mbo] 9: num_iterations=3814; learning_rate=0.0051; feature_fraction=0.704; num_leaves=650; min_data_in_leaf=349; max_depth=7; min_gain_to_split=1.09; bagging_fraction=0.848; bagging_freq=12; lambda_l1=0.782; lambda_l2=1.1; min_sum_hessian_in_leaf=0.0315 : y = 0.931 : 137.2 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:17:23 2025 AUC 0.931096218083091\n",
      "\n",
      "[mbo] 10: num_iterations=4250; learning_rate=0.0113; feature_fraction=0.706; num_leaves=724; min_data_in_leaf=353; max_depth=6; min_gain_to_split=0.806; bagging_fraction=0.922; bagging_freq=12; lambda_l1=1.03; lambda_l2=1.11; min_sum_hessian_in_leaf=0.033 : y = 0.931 : 105.4 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:18:58 2025 AUC 0.93056628830061\n",
      "\n",
      "[mbo] 11: num_iterations=4086; learning_rate=0.0102; feature_fraction=0.715; num_leaves=745; min_data_in_leaf=344; max_depth=7; min_gain_to_split=1.27; bagging_fraction=0.851; bagging_freq=12; lambda_l1=1.74; lambda_l2=2.87; min_sum_hessian_in_leaf=0.0374 : y = 0.931 : 93.8 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:21:27 2025 AUC 0.930509676384324\n",
      "\n",
      "[mbo] 12: num_iterations=3454; learning_rate=0.0106; feature_fraction=0.554; num_leaves=653; min_data_in_leaf=306; max_depth=7; min_gain_to_split=1.71; bagging_fraction=0.908; bagging_freq=12; lambda_l1=0.713; lambda_l2=1.83; min_sum_hessian_in_leaf=0.0231 : y = 0.931 : 147.3 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 13 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Sep 02 02:22:46 2025 AUC 0.931039694272825\n",
      "\n",
      "[mbo] 13: num_iterations=3325; learning_rate=0.011; feature_fraction=0.697; num_leaves=561; min_data_in_leaf=337; max_depth=6; min_gain_to_split=1.27; bagging_fraction=0.938; bagging_freq=10; lambda_l1=1.71; lambda_l2=1.85; min_sum_hessian_in_leaf=0.0268 : y = 0.931 : 72.8 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:24:30 2025 AUC 0.930616014154137\n",
      "\n",
      "[mbo] 14: num_iterations=3586; learning_rate=0.0065; feature_fraction=0.712; num_leaves=522; min_data_in_leaf=314; max_depth=7; min_gain_to_split=1.59; bagging_fraction=0.867; bagging_freq=8; lambda_l1=1.7; lambda_l2=1.57; min_sum_hessian_in_leaf=0.0437 : y = 0.931 : 102.0 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:25:58 2025 AUC 0.929143577195505\n",
      "\n",
      "[mbo] 15: num_iterations=4373; learning_rate=0.00816; feature_fraction=0.735; num_leaves=671; min_data_in_leaf=86; max_depth=6; min_gain_to_split=1.93; bagging_fraction=0.847; bagging_freq=8; lambda_l1=2.8; lambda_l2=2.46; min_sum_hessian_in_leaf=0.0217 : y = 0.929 : 86.6 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:27:10 2025 AUC 0.930798600028606\n",
      "\n",
      "[mbo] 16: num_iterations=3922; learning_rate=0.0118; feature_fraction=0.706; num_leaves=655; min_data_in_leaf=198; max_depth=6; min_gain_to_split=1.8; bagging_fraction=0.837; bagging_freq=12; lambda_l1=2.31; lambda_l2=1.14; min_sum_hessian_in_leaf=0.0427 : y = 0.931 : 70.4 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:29:25 2025 AUC 0.930275190782529\n",
      "\n",
      "[mbo] 17: num_iterations=4127; learning_rate=0.00448; feature_fraction=0.717; num_leaves=602; min_data_in_leaf=349; max_depth=6; min_gain_to_split=1.28; bagging_fraction=0.895; bagging_freq=9; lambda_l1=1.91; lambda_l2=1.11; min_sum_hessian_in_leaf=0.0296 : y = 0.93 : 133.8 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:31:33 2025 AUC 0.929849311358106\n",
      "\n",
      "[mbo] 18: num_iterations=4036; learning_rate=0.00812; feature_fraction=0.627; num_leaves=557; min_data_in_leaf=320; max_depth=7; min_gain_to_split=1.27; bagging_fraction=0.881; bagging_freq=12; lambda_l1=0.65; lambda_l2=1.07; min_sum_hessian_in_leaf=0.034 : y = 0.93 : 125.7 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 19 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Sep 02 02:34:07 2025 AUC 0.930588087918767\n",
      "\n",
      "[mbo] 19: num_iterations=4011; learning_rate=0.00735; feature_fraction=0.662; num_leaves=675; min_data_in_leaf=231; max_depth=6; min_gain_to_split=0.625; bagging_fraction=0.864; bagging_freq=11; lambda_l1=0.578; lambda_l2=1.72; min_sum_hessian_in_leaf=0.0244 : y = 0.931 : 148.6 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:36:26 2025 AUC 0.931707734782014\n",
      "\n",
      "[mbo] 20: num_iterations=3478; learning_rate=0.00512; feature_fraction=0.706; num_leaves=836; min_data_in_leaf=246; max_depth=7; min_gain_to_split=0.812; bagging_fraction=0.841; bagging_freq=8; lambda_l1=1.5; lambda_l2=1.74; min_sum_hessian_in_leaf=0.0455 : y = 0.932 : 138.0 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:38:04 2025 AUC 0.930616999144039\n",
      "\n",
      "[mbo] 21: num_iterations=3679; learning_rate=0.00876; feature_fraction=0.706; num_leaves=698; min_data_in_leaf=329; max_depth=5; min_gain_to_split=1.29; bagging_fraction=0.869; bagging_freq=12; lambda_l1=1.23; lambda_l2=1.09; min_sum_hessian_in_leaf=0.0247 : y = 0.931 : 95.6 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:40:27 2025 AUC 0.931607368319959\n",
      "\n",
      "[mbo] 22: num_iterations=3718; learning_rate=0.00562; feature_fraction=0.71; num_leaves=787; min_data_in_leaf=258; max_depth=7; min_gain_to_split=0.79; bagging_fraction=0.877; bagging_freq=8; lambda_l1=2.05; lambda_l2=1.87; min_sum_hessian_in_leaf=0.0458 : y = 0.932 : 140.9 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:41:46 2025 AUC 0.930943120310131\n",
      "\n",
      "[mbo] 23: num_iterations=3456; learning_rate=0.0113; feature_fraction=0.701; num_leaves=631; min_data_in_leaf=358; max_depth=6; min_gain_to_split=1.3; bagging_fraction=0.865; bagging_freq=12; lambda_l1=2.53; lambda_l2=1.03; min_sum_hessian_in_leaf=0.0516 : y = 0.931 : 78.0 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 24 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Sep 02 02:43:25 2025 AUC 0.930335930325423\n",
      "\n",
      "[mbo] 24: num_iterations=4172; learning_rate=0.0111; feature_fraction=0.705; num_leaves=578; min_data_in_leaf=303; max_depth=6; min_gain_to_split=1.39; bagging_fraction=0.882; bagging_freq=12; lambda_l1=0.801; lambda_l2=1.11; min_sum_hessian_in_leaf=0.0294 : y = 0.93 : 91.9 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:45:49 2025 AUC 0.931207360777933\n",
      "\n",
      "[mbo] 25: num_iterations=3836; learning_rate=0.00646; feature_fraction=0.705; num_leaves=617; min_data_in_leaf=192; max_depth=7; min_gain_to_split=0.813; bagging_fraction=0.879; bagging_freq=8; lambda_l1=2.51; lambda_l2=2.08; min_sum_hessian_in_leaf=0.0392 : y = 0.931 : 142.5 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:48:13 2025 AUC 0.930319726179971\n",
      "\n",
      "[mbo] 26: num_iterations=3653; learning_rate=0.00545; feature_fraction=0.685; num_leaves=762; min_data_in_leaf=186; max_depth=7; min_gain_to_split=0.804; bagging_fraction=0.849; bagging_freq=8; lambda_l1=1.81; lambda_l2=1.04; min_sum_hessian_in_leaf=0.0532 : y = 0.93 : 142.3 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:49:50 2025 AUC 0.930538134134666\n",
      "\n",
      "[mbo] 27: num_iterations=3717; learning_rate=0.0102; feature_fraction=0.703; num_leaves=643; min_data_in_leaf=357; max_depth=6; min_gain_to_split=1.26; bagging_fraction=0.848; bagging_freq=12; lambda_l1=1.21; lambda_l2=1.89; min_sum_hessian_in_leaf=0.0203 : y = 0.931 : 94.9 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:52:06 2025 AUC 0.929749541941877\n",
      "\n",
      "[mbo] 28: num_iterations=3387; learning_rate=0.00555; feature_fraction=0.708; num_leaves=834; min_data_in_leaf=274; max_depth=7; min_gain_to_split=0.798; bagging_fraction=0.816; bagging_freq=8; lambda_l1=1.26; lambda_l2=2.61; min_sum_hessian_in_leaf=0.039 : y = 0.93 : 134.5 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 29 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Sep 02 02:54:06 2025 AUC 0.930396418671002\n",
      "\n",
      "[mbo] 29: num_iterations=3623; learning_rate=0.00625; feature_fraction=0.703; num_leaves=749; min_data_in_leaf=232; max_depth=7; min_gain_to_split=1.47; bagging_fraction=0.826; bagging_freq=8; lambda_l1=1.38; lambda_l2=1.83; min_sum_hessian_in_leaf=0.0439 : y = 0.93 : 113.8 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:55:24 2025 AUC 0.930245797111442\n",
      "\n",
      "[mbo] 30: num_iterations=3643; learning_rate=0.00924; feature_fraction=0.717; num_leaves=608; min_data_in_leaf=95; max_depth=6; min_gain_to_split=1.9; bagging_fraction=0.89; bagging_freq=9; lambda_l1=2.15; lambda_l2=2.12; min_sum_hessian_in_leaf=0.044 : y = 0.93 : 76.0 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:56:35 2025 AUC 0.930086367409655\n",
      "\n",
      "[mbo] 31: num_iterations=1776; learning_rate=0.00593; feature_fraction=0.646; num_leaves=699; min_data_in_leaf=287; max_depth=6; min_gain_to_split=1.06; bagging_fraction=0.867; bagging_freq=7; lambda_l1=1.45; lambda_l2=1.28; min_sum_hessian_in_leaf=0.0262 : y = 0.93 : 69.9 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 02:58:51 2025 AUC 0.930670217323932\n",
      "\n",
      "[mbo] 32: num_iterations=3260; learning_rate=0.00525; feature_fraction=0.707; num_leaves=791; min_data_in_leaf=259; max_depth=7; min_gain_to_split=0.69; bagging_fraction=0.842; bagging_freq=8; lambda_l1=1.37; lambda_l2=1.7; min_sum_hessian_in_leaf=0.0277 : y = 0.931 : 134.0 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 03:00:56 2025 AUC 0.930203631128682\n",
      "\n",
      "[mbo] 33: num_iterations=3967; learning_rate=0.0109; feature_fraction=0.746; num_leaves=649; min_data_in_leaf=245; max_depth=6; min_gain_to_split=0.702; bagging_fraction=0.89; bagging_freq=11; lambda_l1=1.02; lambda_l2=1.11; min_sum_hessian_in_leaf=0.0378 : y = 0.93 : 123.3 secs : infill_ei\n",
      "\n",
      "Tue Sep 02 03:02:28 2025 AUC 0.929890415761516\n",
      "\n",
      "[mbo] 34: num_iterations=2286; learning_rate=0.0053; feature_fraction=0.619; num_leaves=876; min_data_in_leaf=272; max_depth=5; min_gain_to_split=1.31; bagging_fraction=0.945; bagging_freq=12; lambda_l1=0.535; lambda_l2=2.62; min_sum_hessian_in_leaf=0.0356 : y = 0.93 : 90.7 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 35 in the file bayesiana.RDATA.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "# es la celda mas lenta de todo el notebook\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssk5nnMk6INK"
   },
   "outputs": [],
   "source": [
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "colnames( tb_bayesiana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4zq-vknhjGc"
   },
   "outputs": [],
   "source": [
    "# almaceno los resultados de la Bayesian Optimization\n",
    "# y capturo los mejores hiperparametros encontrados\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "\n",
    "tb_bayesiana[, iter := .I]\n",
    "\n",
    "# ordeno en forma descendente por AUC = y\n",
    "setorder(tb_bayesiana, -y)\n",
    "\n",
    "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
    "fwrite( tb_bayesiana,\n",
    "  file= \"BO_log.txt\",\n",
    "  sep= \"\\t\"\n",
    ")\n",
    "\n",
    "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
    "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
    "  1, # el primero es el de mejor AUC\n",
    "  setdiff(colnames(tb_bayesiana),\n",
    "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
    "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
    "  with= FALSE\n",
    "]\n",
    "\n",
    "\n",
    "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8v2eA427N8e"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBTWexVU7PGC"
   },
   "outputs": [],
   "source": [
    "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
    "print(PARAM$out$lgbm$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKsVZmAnhwX-"
   },
   "source": [
    "## 2.3  Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ_C33Tr5B_9"
   },
   "source": [
    "### Final Training\n",
    "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDqfyA14hzwv"
   },
   "outputs": [],
   "source": [
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento <- paste0(\"exp\", PARAM$experimento)\n",
    "dir.create(experimento, showWarnings= FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qFmFivf5Iet"
   },
   "source": [
    "#### Final Training Dataset\n",
    "\n",
    "Aqui esta la gran decision de en qué meses hago el Final Training\n",
    "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lg5WVZncvc7H"
   },
   "outputs": [],
   "source": [
    "# clase01\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yc9QzXREv0xf"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thjdqEBLuvNt"
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[, clase01]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNUa-WSz5Oqu"
   },
   "source": [
    "#### Final Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgCcvBfEwImu"
   },
   "outputs": [],
   "source": [
    "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
    "  PARAM$out$lgbm$mejores_hiperparametros)\n",
    "\n",
    "param_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZIYn4l95TBH"
   },
   "source": [
    "#### Training\n",
    "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPLsd4mMRe4u"
   },
   "outputs": [],
   "source": [
    "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
    "\n",
    "param_normalizado <- copy(param_final)\n",
    "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRI_-taRwOXO"
   },
   "outputs": [],
   "source": [
    "  # entreno LightGBM\n",
    "\n",
    "  modelo_final <- lgb.train(\n",
    "    data= dtrain,\n",
    "    param= param_normalizado\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bkhnCvj0g3Q"
   },
   "outputs": [],
   "source": [
    "# ahora imprimo la importancia de variables\n",
    "\n",
    "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
    "archivo_importancia <- \"impo.txt\"\n",
    "\n",
    "fwrite(tb_importancia,\n",
    "  file= archivo_importancia,\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZ3sLmbh0kFj"
   },
   "outputs": [],
   "source": [
    "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
    "\n",
    "lgb.save(modelo_final, \"modelo.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEtp2--t5Ymg"
   },
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI5008Mj5ZdI"
   },
   "source": [
    "Aplico el modelo final a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PimBY3N_0ryP"
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes == 202109]\n",
    "\n",
    "# aplico el modelo a los datos nuevos\n",
    "prediccion <- predict(\n",
    "  modelo_final,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D26rNRh55gpw"
   },
   "source": [
    "#### Tabla Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJwg7LHd11yu"
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "Kaggle Competition Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWW3tatE12je"
   },
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "# suba TODOS los archivos a Kaggle\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "dir.create(\"kaggle\")\n",
    "\n",
    "for (envios in PARAM$kaggle$cortes) {\n",
    "\n",
    "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
    "\n",
    "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "    file= archivo_kaggle,\n",
    "    sep= \",\"\n",
    "  )\n",
    "\n",
    "  # subida a Kaggle, armo la linea de comando\n",
    "  comando <- \"kaggle competitions submit\"\n",
    "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
    "  arch <- paste( \"-f\", archivo_kaggle)\n",
    "\n",
    "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
    "  \"  semilla=\", PARAM$semilla_primigenia,\n",
    "    \"'\" )\n",
    "\n",
    "  linea <- paste( comando, competencia, arch, mensaje)\n",
    "\n",
    "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
    "  cat(salida, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9tB2X4439Hg"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zA_W25c15DP"
   },
   "outputs": [],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdVZucdLHzZ0"
   },
   "source": [
    "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
    "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
